{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfee6199-a091-4669-b3e6-7b140d8e9535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.38.2\n",
      "  Using cached transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
      "Collecting accelerate==0.28.0\n",
      "  Using cached accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting peft==0.9.0\n",
      "  Using cached peft-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: bitsandbytes>=0.41.3 in /usr/local/lib/python3.10/dist-packages (0.46.1)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.5)\n",
      "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
      "Requirement already satisfied: bert_score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
      "Requirement already satisfied: unbabel-comet in /usr/local/lib/python3.10/dist-packages (2.2.6)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (2025.7.34)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (2.32.4)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.2)\n",
      "  Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0) (2.7.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (2.3.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.10.5)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (3.2.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (6.0.0)\n",
      "Requirement already satisfied: entmax<2.0,>=1.1 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (1.3)\n",
      "Requirement already satisfied: jsonargparse==3.13.1 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (3.13.1)\n",
      "Requirement already satisfied: protobuf<5.0.0,>=4.24.4 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (4.25.8)\n",
      "Requirement already satisfied: pytorch-lightning<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (2.5.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (1.15.3)\n",
      "Requirement already satisfied: sentencepiece<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (0.2.0)\n",
      "Requirement already satisfied: torchmetrics<0.11.0,>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (0.10.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.2) (2025.7.14)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/dist-packages (from triton==3.3.1->torch>=1.10.0->accelerate==0.28.0) (69.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->bert_score) (2.4.7)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.2.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.5.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.28.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.28.0) (3.0.2)\n",
      "Using cached transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "Using cached accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "Using cached peft-0.9.0-py3-none-any.whl (190 kB)\n",
      "Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Installing collected packages: tokenizers, transformers, accelerate, peft\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.4\n",
      "    Uninstalling tokenizers-0.21.4:\n",
      "      Successfully uninstalled tokenizers-0.21.4\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.54.1\n",
      "    Uninstalling transformers-4.54.1:\n",
      "      Successfully uninstalled transformers-4.54.1\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.9.0\n",
      "    Uninstalling accelerate-1.9.0:\n",
      "      Successfully uninstalled accelerate-1.9.0\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.17.0\n",
      "    Uninstalling peft-0.17.0:\n",
      "      Successfully uninstalled peft-0.17.0\n",
      "Successfully installed accelerate-0.28.0 peft-0.9.0 tokenizers-0.15.2 transformers-4.38.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 1. SETUP AND INSTALLATIONS\n",
    "# ==============================================================================\n",
    "%pip install --upgrade \\\n",
    "    \"transformers==4.38.2\" \\\n",
    "    \"accelerate==0.28.0\" \\\n",
    "    \"peft==0.9.0\" \\\n",
    "    \"bitsandbytes>=0.41.3\" \\\n",
    "    \"evaluate\" \\\n",
    "    \"rouge_score\" \\\n",
    "    \"bert_score\" \\\n",
    "    \"sacrebleu\" \\\n",
    "    \"unbabel-comet\"\n",
    "\n",
    "# After this cell finishes, you MUST restart the kernel for the updates to take effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0dd9ca2-9a33-47c4-9473-ce0cd3e112a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete. Please restart the kernel now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Upgrade all the necessary libraries to ensure compatibility\n",
    "os.system(\"pip install --upgrade --quiet transformers peft accelerate bitsandbytes\")\n",
    "\n",
    "print(\"Environment setup complete. Please restart the kernel now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01e50ff1-8964-407c-b072-d96ddbec0c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af09e0bd84f4fe0914c98a7595f5de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/836 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54dbdc9f5c6e4344bf38c5dfefe29588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359200359ff74fc79609cdade0f4a84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0067ea6f143416ca9fde443265d378f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00011.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09498e45210482fbb1dcda6b13226da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00011.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52ff145533c47c08251132fa1951dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00011.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a560a231e7f49d4969d6c5f659816a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00011.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95eb7f9c181c4b84a601c611b3d875f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00011.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce11a13c84c6479b8c7c3ee7f4aa46d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00011.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46f8c89f7e846a9a982f54e51422c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00011.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d6d52df13d4e0b8b1849c443b8995d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00011.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88373a83d9d14c74bd88248da0ef6378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00011.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f03c1db88f5499582a92f7e0b51a29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00011.safetensors:   0%|          | 0.00/2.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba7e0d2acd54664b4a2dc8693eb0166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00011-of-00011.safetensors:   0%|          | 0.00/4.10G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34677341e824a21b115c3de98f3e21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90d70e79dbb4ba8b11de0c7c8ebf9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5325a7b6d6b46e882cdd18d63f97471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/833 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632f18f6e9a74cb3b829ad8fa5192175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LoRA adapter from: ./results_aya_101/final_checkpoint\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 2. CONFIGURATION AND MODEL LOADING\n",
    "# ==============================================================================\n",
    "import os\n",
    "import torch\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "class EvalConfig:\n",
    "    # Path to the base model\n",
    "    MODEL_ID = \"CohereLabs/aya-101\"\n",
    "    \n",
    "    # Path to your trained LoRA adapter.\n",
    "    # VERIFY this path matches the output of your training script.\n",
    "    ADAPTER_PATH = \"./results_aya_101/final_checkpoint\"\n",
    "    \n",
    "    # Dataset configuration\n",
    "    DATASET_NAME = \"RobbedoesHF/dutch-definitions\"\n",
    "    DATASET_TEST_SPLIT = \"test\"\n",
    "    \n",
    "    # Generation parameters\n",
    "    MAX_SOURCE_LENGTH = 256\n",
    "    MAX_TARGET_LENGTH = 384\n",
    "    BATCH_SIZE = 16\n",
    "    \n",
    "config = EvalConfig()\n",
    "\n",
    "# --- Model and Tokenizer Loading ---\n",
    "print(\"Loading base model and tokenizer...\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    config.MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "# Load the tokenizer with trust_remote_code=True\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    config.MODEL_ID,\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Loading LoRA adapter from: {config.ADAPTER_PATH}\")\n",
    "model = PeftModel.from_pretrained(model, config.ADAPTER_PATH)\n",
    "\n",
    "model.eval()\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e62bcc23-606b-4537-81d3-79b0b0cd53ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset and preparing for generation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1990e62a8b1745758142c2fcfceaf816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/723 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8a1d5132b24ffea7cfa95f7a29fac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/2.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb9122cdc17405a98636b43e67081cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/381k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fd5f4006964e73a6339f751dc03487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/379k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9423a5a968434dbabd3c708ba16c2507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/27880 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf40f5934c44557b64dc250659dd38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3494 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd628188817432bb4d9ed62db6d9a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for 3450 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [20:19<00:00,  5.65s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation complete. Example result:\n",
      "                                              source  \\\n",
      "0  Je bent een expert-lexicograaf die definities ...   \n",
      "1  Je bent een expert-lexicograaf die definities ...   \n",
      "2  Je bent een expert-lexicograaf die definities ...   \n",
      "3  Je bent een expert-lexicograaf die definities ...   \n",
      "4  Je bent een expert-lexicograaf die definities ...   \n",
      "\n",
      "                                          prediction  \\\n",
      "0  maatschappij waarin iedereen minimaal 1,5 mete...   \n",
      "1  centrale waarop de politie en de hulpdiensten ...   \n",
      "2  bankbiljet dat de waarde van 200 euro vertegen...   \n",
      "3                   monitor die 3D-beelden weergeeft   \n",
      "4  autootje met de status van een bromfiets en ee...   \n",
      "\n",
      "                                           reference  \n",
      "0  maatschappij waarin mensen die niet tot hetzel...  \n",
      "1  alarmcentrale die bereikbaar is onder het tele...  \n",
      "2  bankbiljet dat de waarde van 200 euro vertegen...  \n",
      "3       monitor die driedimensionaal beeld weergeeft  \n",
      "4  motorvoertuig met de officiële status van een ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 3. GENERATE PREDICTIONS FOR THE TEST SET\n",
    "# ==============================================================================\n",
    "print(\"Loading test dataset and preparing for generation...\")\n",
    "dataset = load_dataset(config.DATASET_NAME, split=config.DATASET_TEST_SPLIT)\n",
    "\n",
    "# We will store the results here\n",
    "results = []\n",
    "\n",
    "# This function creates the simple prompt string used during AYA 101 fine-tuning.\n",
    "def create_inference_prompt(lemma, short_def):\n",
    "    \"\"\"\n",
    "    Creates a single formatted prompt string for inference, matching the training format.\n",
    "    \"\"\"\n",
    "    # Define the role-playing system prompt as used in training\n",
    "    system_prompt = \"Je bent een expert-lexicograaf die definities schrijft voor een Nederlands woordenboek.\" #\n",
    "    \n",
    "    # Combine the system prompt with the task-specific instruction\n",
    "    return f\"{system_prompt}\\\\n\\\\nBreid de volgende korte definitie voor het woord '{lemma}' uit tot een volledige definitie: '{short_def}'\" #\n",
    "\n",
    "print(f\"Generating predictions for {len(dataset)} samples...\")\n",
    "# Process the dataset in batches for efficiency\n",
    "for i in tqdm(range(0, len(dataset), config.BATCH_SIZE)):\n",
    "    batch = dataset[i:i+config.BATCH_SIZE]\n",
    "\n",
    "    # Create the input prompts\n",
    "    prompts = [\n",
    "        create_inference_prompt(lemma, short_def)\n",
    "        for lemma, short_def in zip(batch['Lemma'], batch['DefinitionShort'])\n",
    "    ]\n",
    "\n",
    "    # The 'source' for COMET is the full input prompt\n",
    "    sources = prompts\n",
    "\n",
    "    # Tokenize the batch of prompts\n",
    "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=config.MAX_SOURCE_LENGTH).to(\"cuda\")\n",
    "\n",
    "    # Generate outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=config.MAX_TARGET_LENGTH,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # Decode the generated sequences\n",
    "    predictions = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    # Store the results\n",
    "    for j in range(len(predictions)):\n",
    "        results.append({\n",
    "            \"source\": sources[j],\n",
    "            \"prediction\": predictions[j],\n",
    "            \"reference\": batch['DefinitionFull'][j]\n",
    "        })\n",
    "\n",
    "# Convert results to a pandas DataFrame for easier handling\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nGeneration complete. Example result:\")\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee65e4a7-7934-4b9a-9bf9-ab7e918be96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics...\n",
      "\n",
      "--- ROUGE Scores ---\n",
      "{'rouge1': 0.40284882839281466, 'rouge2': 0.2373084287696915, 'rougeL': 0.3780132098671784, 'rougeLsum': 0.3784015137868909}\n",
      "\n",
      "--- BLEU Score ---\n",
      "{'bleu': 0.10628725926459942, 'precisions': [0.510846345939766, 0.28280793634807133, 0.18753085013479137, 0.14034321645342998], 'brevity_penalty': 0.4280255563172645, 'length_ratio': 0.5409579922201787, 'translation_length': 33237, 'reference_length': 61441}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BERTScore ---\n",
      "   Average Precision: 0.8075\n",
      "      Average Recall: 0.7561\n",
      "          Average F1: 0.7796\n",
      "\n",
      "--- COMET Scores ---\n",
      "Loading COMET models (this may take a while)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c58c5d2757b4a608e811952e2c8d71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27dc13646484272a57fd1191aabf166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f8bc09b9e647de8cedf8ca920fd0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abbffb4ff2094145be0fbd066b1579e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "checkpoints/model.ckpt:   0%|          | 0.00/2.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381505a7950943d9bf9f0214a4825316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hparams.yaml:   0%|          | 0.00/716 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.8.2 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/huggingface/hub/models--Unbabel--wmt22-cometkiwi-da/snapshots/1ad785194e391eebc6c53e2d0776cada8f83179a/checkpoints/model.ckpt`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0645dec934be422c930d32f367d4d46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d639c3a50bdf4408ae3865147870dfb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d59735dfafd466b8cc8823f7334973c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/513 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eadf8e98f894b53bf790e45bc33a1c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1e5fbc699640f5950b9aa106c6d105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6443aeec8f4759acdbd1d3f7c7cf3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202ae65b0c714a8c985171218f46b0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2614a174656845d0abe208224ce592e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "checkpoints/model.ckpt:   0%|          | 0.00/13.9G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb9a5f71fdc441680389400f3c101e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hparams.yaml:   0%|          | 0.00/988 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78b4653b6514158ae63e9430dd104d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/405 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39445fdf13440169525f2bb359e7444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9b5898f7d14dd8a542c007710e0e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4796736377934e09b021022ddfa4a948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/238 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d574bf30755d4f3f888b64756b224b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- COMET-22 Score ---\n",
      "               score: 0.6536\n",
      "\n",
      "--- COMETkiwi Score ---\n",
      "               score: 0.6165\n",
      "\n",
      "--- XCOMET Score ---\n",
      "               score: 0.6298\n",
      "\n",
      "Saving results to disk...\n",
      "Summary of scores saved to: ./evaluation_summary_aya-101.txt\n",
      "\n",
      "Evaluation finished.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 4. CALCULATE AND DISPLAY METRICS\n",
    "# ==============================================================================\n",
    "print(\"Calculating evaluation metrics...\")\n",
    "\n",
    "# Extract lists of predictions, references, and sources from the DataFrame\n",
    "predictions = results_df[\"prediction\"].tolist()\n",
    "references = results_df[\"reference\"].tolist()\n",
    "sources = results_df[\"source\"].tolist()\n",
    "\n",
    "# --- ROUGE ---\n",
    "rouge = evaluate.load('rouge')\n",
    "rouge_results = rouge.compute(predictions=predictions, references=references)\n",
    "print(\"\\n--- ROUGE Scores ---\")\n",
    "print(rouge_results)\n",
    "\n",
    "# --- BLEU ---\n",
    "bleu = evaluate.load('bleu')\n",
    "# Note: BLEU expects references to be a list of lists\n",
    "bleu_results = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "print(\"\\n--- BLEU Score ---\")\n",
    "print(bleu_results)\n",
    "\n",
    "# --- BERTScore ---\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "bertscore_results = bertscore.compute(predictions=predictions, references=references, lang=\"nl\")\n",
    "\n",
    "avg_precision = sum(bertscore_results['precision']) / len(bertscore_results['precision'])\n",
    "avg_recall = sum(bertscore_results['recall']) / len(bertscore_results['recall'])\n",
    "avg_f1 = sum(bertscore_results['f1']) / len(bertscore_results['f1'])\n",
    "\n",
    "print(f\"\\n--- BERTScore ---\")\n",
    "print(f\"{'Average Precision':>20}: {avg_precision:.4f}\")\n",
    "print(f\"{'Average Recall':>20}: {avg_recall:.4f}\")\n",
    "print(f\"{'Average F1':>20}: {avg_f1:.4f}\")\n",
    "\n",
    "# --- COMET ---\n",
    "print(\"\\n--- COMET Scores ---\")\n",
    "print(\"Loading COMET models (this may take a while)...\")\n",
    "comet_22 = evaluate.load('comet', 'Unbabel/wmt22-comet-da')\n",
    "comet_kiwi = evaluate.load('comet', 'Unbabel/wmt22-cometkiwi-da')\n",
    "xcomet = evaluate.load('comet', 'Unbabel/XCOMET-XL')\n",
    "\n",
    "comet_22_results = comet_22.compute(predictions=predictions, references=references, sources=sources)\n",
    "comet_kiwi_results = comet_kiwi.compute(predictions=predictions, references=references, sources=sources)\n",
    "xcomet_results = xcomet.compute(predictions=predictions, references=references, sources=sources)\n",
    "\n",
    "print(f\"\\n--- COMET-22 Score ---\")\n",
    "print(f\"{'score':>20}: {comet_22_results['mean_score']:.4f}\")\n",
    "print(f\"\\n--- COMETkiwi Score ---\")\n",
    "print(f\"{'score':>20}: {comet_kiwi_results['mean_score']:.4f}\")\n",
    "print(f\"\\n--- XCOMET Score ---\")\n",
    "print(f\"{'score':>20}: {xcomet_results['mean_score']:.4f}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. SAVE RESULTS TO DISK\n",
    "# ==============================================================================\n",
    "print(\"\\nSaving results to disk...\")\n",
    "\n",
    "# --- Save the summary scores to a text file ---\n",
    "summary_path = \"./evaluation_summary_aya-101.txt\"\n",
    "with open(summary_path, \"w\") as f:\n",
    "    f.write(\"--- ROUGE Scores ---\\n\")\n",
    "    f.write(str(rouge_results) + \"\\n\")\n",
    "    f.write(\"\\n--- BLEU Score ---\\n\")\n",
    "    f.write(str(bleu_results) + \"\\n\")\n",
    "    f.write(\"\\n--- BERTScore ---\\n\")\n",
    "    f.write(f\"{'Average Precision':>20}: {avg_precision:.4f}\\n\")\n",
    "    f.write(f\"{'Average Recall':>20}: {avg_recall:.4f}\\n\")\n",
    "    f.write(f\"{'Average F1':>20}: {avg_f1:.4f}\\n\")\n",
    "    f.write(\"\\n--- COMET-22 Score ---\\n\")\n",
    "    f.write(f\"{'score':>20}: {comet_22_results['mean_score']:.4f}\\n\")\n",
    "    f.write(\"\\n--- COMETkiwi Score ---\\n\")\n",
    "    f.write(f\"{'score':>20}: {comet_kiwi_results['mean_score']:.4f}\\n\")\n",
    "    f.write(\"\\n--- XCOMET Score ---\\n\")\n",
    "    f.write(f\"{'score':>20}: {xcomet_results['mean_score']:.4f}\\n\")\n",
    "\n",
    "print(f\"Summary of scores saved to: {summary_path}\")\n",
    "print(\"\\nEvaluation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cde55c85-ed61-427b-ae7f-9d2ed8323a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating a detailed results file with per-entry scores ---\n",
      "\n",
      "Successfully created and saved the detailed results file.\n",
      "File saved to: ./evaluation_results_per_entry_aya-101.tsv\n",
      "\n",
      "--- Data Preview ---\n",
      "Note: BLEU and ROUGE are corpus-level metrics and are not included in this per-entry file.\n",
      "                   Lemma          POS MeaningNumber  LemmaID  MeaningID  \\\n",
      "0  1,5 metermaatschappij  substantief           1.0   909355     909359   \n",
      "1           112-centrale  substantief           1.0      313        314   \n",
      "2         200 eurobiljet  substantief           1.0   495566     495570   \n",
      "3             3D-monitor  substantief           1.0   232019     232022   \n",
      "4      45 kilometerwagen  substantief           1.0   871087     871098   \n",
      "\n",
      "                                      DefinitionFull  \\\n",
      "0  maatschappij waarin mensen die niet tot hetzel...   \n",
      "1  alarmcentrale die bereikbaar is onder het tele...   \n",
      "2  bankbiljet dat de waarde van 200 euro vertegen...   \n",
      "3       monitor die driedimensionaal beeld weergeeft   \n",
      "4  motorvoertuig met de officiële status van een ...   \n",
      "\n",
      "                                DefinitionShort  \\\n",
      "0  maatschappij waarin fysieke afstand nodig is   \n",
      "1                                 alarmcentrale   \n",
      "2                           biljet van 200 euro   \n",
      "3                          monitor met 3D-beeld   \n",
      "4                  autootje met bromfietsstatus   \n",
      "\n",
      "                                    model_prediction  bertscore_precision  \\\n",
      "0  maatschappij waarin iedereen minimaal 1,5 mete...             0.819386   \n",
      "1  centrale waarop de politie en de hulpdiensten ...             0.645940   \n",
      "2  bankbiljet dat de waarde van 200 euro vertegen...             1.000000   \n",
      "3                   monitor die 3D-beelden weergeeft             0.893263   \n",
      "4  autootje met de status van een bromfiets en ee...             0.842275   \n",
      "\n",
      "   bertscore_recall  bertscore_f1  comet22_score  cometkiwi_score  \\\n",
      "0          0.762761      0.790060       0.719838         0.696347   \n",
      "1          0.643664      0.644800       0.706142         0.622212   \n",
      "2          1.000000      1.000000       0.968546         0.633919   \n",
      "3          0.849576      0.870872       0.820027         0.733886   \n",
      "4          0.774680      0.807065       0.691562         0.583628   \n",
      "\n",
      "   xcomet_score  \n",
      "0      0.793221  \n",
      "1      0.432655  \n",
      "2      0.892676  \n",
      "3      0.828547  \n",
      "4      0.876713  \n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 6. CREATE AND SAVE DETAILED PER-ENTRY RESULTS TSV\n",
    "# ==============================================================================\n",
    "print(\"--- Creating a detailed results file with per-entry scores ---\")\n",
    "\n",
    "try:\n",
    "    # Convert the original test set to a pandas DataFrame\n",
    "    final_results_df = dataset.to_pandas()\n",
    "\n",
    "    # Add the model's predictions from the generation step\n",
    "    final_results_df['model_prediction'] = results_df['prediction']\n",
    "\n",
    "    # --- Add Per-Entry Metric Scores ---\n",
    "    # Add BERTScore (Precision, Recall, and F1)\n",
    "    final_results_df['bertscore_precision'] = bertscore_results['precision']\n",
    "    final_results_df['bertscore_recall'] = bertscore_results['recall']\n",
    "    final_results_df['bertscore_f1'] = bertscore_results['f1']\n",
    "    \n",
    "    # Add COMET-22, CometKiwi and XCOMET scores\n",
    "    final_results_df['comet22_score'] = comet_22_results['scores']\n",
    "    final_results_df['cometkiwi_score'] = comet_kiwi_results['scores']\n",
    "    final_results_df['xcomet_score'] = xcomet_results['scores']\n",
    "\n",
    "    # --- Save to TSV File ---\n",
    "    tsv_path = \"./evaluation_results_per_entry_aya-101.tsv\"\n",
    "    final_results_df.to_csv(tsv_path, sep='\\t', index=False)\n",
    "\n",
    "    print(f\"\\nSuccessfully created and saved the detailed results file.\")\n",
    "    print(f\"File saved to: {tsv_path}\")\n",
    "    \n",
    "    print(\"\\n--- Data Preview ---\")\n",
    "    print(\"Note: BLEU and ROUGE are corpus-level metrics and are not included in this per-entry file.\")\n",
    "    print(final_results_df.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred while creating the TSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45661e-5e0d-4182-8569-d44e2b8c5a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
