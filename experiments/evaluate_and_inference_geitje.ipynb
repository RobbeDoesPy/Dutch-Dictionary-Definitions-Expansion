{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfee6199-a091-4669-b3e6-7b140d8e9535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft>=0.11.1\n",
      "  Downloading peft-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: bitsandbytes>=0.43.1 in /usr/local/lib/python3.10/dist-packages (0.46.1)\n",
      "Requirement already satisfied: transformers>=4.42.3 in /usr/local/lib/python3.10/dist-packages (4.42.3)\n",
      "Collecting transformers>=4.42.3\n",
      "  Downloading transformers-4.54.1-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting accelerate>=0.31.0\n",
      "  Downloading accelerate-1.9.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.5)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bert_score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "Collecting unbabel-comet\n",
      "  Downloading unbabel_comet-2.2.6-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft>=0.11.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft>=0.11.1) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft>=0.11.1) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft>=0.11.1) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft>=0.11.1) (2.2.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft>=0.11.1) (4.67.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft>=0.11.1) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft>=0.11.1) (0.34.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (4.14.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.11.1) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft>=0.11.1) (12.9.86)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.3) (2025.7.34)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.3) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.42.3)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.25.0->peft>=0.11.1) (1.1.5)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.19.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
      "Collecting absl-py (from rouge_score)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting nltk (from rouge_score)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\n",
      "Collecting matplotlib (from bert_score)\n",
      "  Downloading matplotlib-3.10.5-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting colorama (from sacrebleu)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (6.0.0)\n",
      "Collecting entmax<2.0,>=1.1 (from unbabel-comet)\n",
      "  Downloading entmax-1.3-py3-none-any.whl.metadata (348 bytes)\n",
      "Collecting jsonargparse==3.13.1 (from unbabel-comet)\n",
      "  Downloading jsonargparse-3.13.1-py3-none-any.whl.metadata (55 kB)\n",
      "Collecting protobuf<5.0.0,>=4.24.4 (from unbabel-comet)\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting pytorch-lightning<3.0.0,>=2.0.0 (from unbabel-comet)\n",
      "  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (1.13.1)\n",
      "Requirement already satisfied: sentencepiece<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (0.2.0)\n",
      "Collecting torchmetrics<0.11.0,>=0.10.2 (from unbabel-comet)\n",
      "  Downloading torchmetrics-0.10.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet)\n",
      "  Downloading lightning_utilities-0.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.7)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets>=2.0.0->evaluate) (3.10)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (69.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.42.3) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.42.3) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.42.3) (2025.7.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft>=0.11.1) (3.0.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->bert_score)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->bert_score)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->bert_score)\n",
      "  Downloading fonttools-4.59.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (107 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->bert_score)\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->bert_score) (2.4.7)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.2.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft>=0.11.1) (1.3.0)\n",
      "Downloading peft-0.16.0-py3-none-any.whl (472 kB)\n",
      "Downloading transformers-4.54.1-py3-none-any.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m201.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.9.0-py3-none-any.whl (367 kB)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "Downloading unbabel_comet-2.2.6-py3-none-any.whl (90 kB)\n",
      "Downloading jsonargparse-3.13.1-py3-none-any.whl (101 kB)\n",
      "Downloading entmax-1.3-py3-none-any.whl (13 kB)\n",
      "Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m136.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.7/529.7 kB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.15.0-py3-none-any.whl (29 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading matplotlib-3.10.5-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m145.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m197.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m196.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Building wheels for collected packages: rouge_score\n",
      "\u001b[33m  DEPRECATION: Building 'rouge_score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge_score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=0d36a291a1bf4cdff85e26cfc3f8cb87a64f768cc465e15c51482da6346768e2\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: tabulate, protobuf, portalocker, nltk, lightning-utilities, kiwisolver, jsonargparse, fonttools, cycler, contourpy, colorama, absl-py, sacrebleu, rouge_score, matplotlib, tokenizers, transformers, torchmetrics, entmax, accelerate, pytorch-lightning, peft, bert_score, unbabel-comet\n",
      "\u001b[2K  Attempting uninstall: protobuf\n",
      "\u001b[2K    Found existing installation: protobuf 3.20.3\n",
      "\u001b[2K    Uninstalling protobuf-3.20.3:\n",
      "\u001b[2K      Successfully uninstalled protobuf-3.20.3━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/24\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: tokenizersm\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/24\u001b[0m [matplotlib]\n",
      "\u001b[2K    Found existing installation: tokenizers 0.19.1━━━━━━━━━━━━\u001b[0m \u001b[32m14/24\u001b[0m [matplotlib]\n",
      "\u001b[2K    Uninstalling tokenizers-0.19.1:m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/24\u001b[0m [matplotlib]\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.19.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/24\u001b[0m [matplotlib]\n",
      "\u001b[2K  Attempting uninstall: transformers╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/24\u001b[0m [matplotlib]\n",
      "\u001b[2K    Found existing installation: transformers 4.42.3━━━━━━━━━━\u001b[0m \u001b[32m14/24\u001b[0m [matplotlib]\n",
      "\u001b[2K    Uninstalling transformers-4.42.3:m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m16/24\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.42.3━━━━━━━━━━━━\u001b[0m \u001b[32m16/24\u001b[0m [transformers]\n",
      "\u001b[2K  Attempting uninstall: accelerate━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m17/24\u001b[0m [torchmetrics]\n",
      "\u001b[2K    Found existing installation: accelerate 0.28.0m━━━━━━━━━━━\u001b[0m \u001b[32m17/24\u001b[0m [torchmetrics]\n",
      "\u001b[2K    Uninstalling accelerate-0.28.0:m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m17/24\u001b[0m [torchmetrics]\n",
      "\u001b[2K      Successfully uninstalled accelerate-0.28.090m━━━━━━━━━━━\u001b[0m \u001b[32m17/24\u001b[0m [torchmetrics]\n",
      "\u001b[2K  Attempting uninstall: peft━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m20/24\u001b[0m [pytorch-lightning]\n",
      "\u001b[2K    Found existing installation: peft 0.9.090m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m20/24\u001b[0m [pytorch-lightning]\n",
      "\u001b[2K    Uninstalling peft-0.9.0:━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m20/24\u001b[0m [pytorch-lightning]\n",
      "\u001b[2K      Successfully uninstalled peft-0.9.0\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m20/24\u001b[0m [pytorch-lightning]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/24\u001b[0m [unbabel-comet]0m [bert_score]ng]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 accelerate-1.9.0 bert_score-0.3.13 colorama-0.4.6 contourpy-1.3.2 cycler-0.12.1 entmax-1.3 fonttools-4.59.0 jsonargparse-3.13.1 kiwisolver-1.4.8 lightning-utilities-0.15.0 matplotlib-3.10.5 nltk-3.9.1 peft-0.16.0 portalocker-3.2.0 protobuf-4.25.8 pytorch-lightning-2.5.2 rouge_score-0.1.2 sacrebleu-2.5.1 tabulate-0.9.0 tokenizers-0.21.4 torchmetrics-0.10.3 transformers-4.54.1 unbabel-comet-2.2.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 1. SETUP AND INSTALLATIONS\n",
    "# ==============================================================================\n",
    "%pip install --upgrade \\\n",
    "    \"peft>=0.11.1\" \\\n",
    "    \"bitsandbytes>=0.43.1\" \\\n",
    "    \"transformers>=4.42.3\" \\\n",
    "    \"accelerate>=0.31.0\" \\\n",
    "    \"evaluate\" \\\n",
    "    \"rouge_score\" \\\n",
    "    \"bert_score\" \\\n",
    "    \"sacrebleu\" \\\n",
    "    \"unbabel-comet\"\n",
    "\n",
    "# After this cell finishes, you MUST restart the kernel for the updates to take effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e50ff1-8964-407c-b072-d96ddbec0c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71faaf62e7cb4a45805601c1d03b2560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ec82e6857340d7ba6c9d1d8ca944c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ea9d70fc2b4a6a90ac12a30143f861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753445840f66417292ee459aa5f076ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bc7c1d7aab4ee2a775785fe29f962f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813338dd7a85420fa94ecb66b17489cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8981eaaf066945bbae73dcbc8d1cfaef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e3cf0be4324d0d909560f3293e2177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1421e9eff344b0be43cc80b676251b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bb67e2d7464ba698722d7e3b995f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98d8982b4cf4be185c0cfa72f809db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0095af93071f4781857896792c0f2e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LoRA adapter from: ./results_geitje_7b_ultra/final_checkpoint\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 2. CONFIGURATION AND MODEL LOADING\n",
    "# ==============================================================================\n",
    "import os\n",
    "import torch\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "class EvalConfig:\n",
    "    # Path to the base model\n",
    "    MODEL_ID = \"bramvanroy/geitje-7b-ultra\"\n",
    "    \n",
    "    # Path to your trained LoRA adapter.\n",
    "    # VERIFY this path matches the output of your training script.\n",
    "    ADAPTER_PATH = \"./results_geitje_7b_ultra/final_checkpoint\"\n",
    "    \n",
    "    # Dataset configuration\n",
    "    DATASET_NAME = \"RobbedoesHF/dutch-definitions\"\n",
    "    DATASET_TEST_SPLIT = \"test\"\n",
    "    \n",
    "    # Generation parameters\n",
    "    MAX_SEQ_LENGTH = 512\n",
    "    BATCH_SIZE = 32  # Adjust based on your GPU memory\n",
    "\n",
    "config = EvalConfig()\n",
    "\n",
    "# --- Model and Tokenizer Loading ---\n",
    "print(\"Loading base model and tokenizer...\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.MODEL_ID)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f\"Loading LoRA adapter from: {config.ADAPTER_PATH}\")\n",
    "model = PeftModel.from_pretrained(model, config.ADAPTER_PATH)\n",
    "\n",
    "model.eval()\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f021e1e-a501-4b05-908c-f236bce03059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset and preparing for generation...\n",
      "Generating predictions for 3450 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [37:19<00:00, 20.74s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation complete. Example result:\n",
      "                                              source  \\\n",
      "0  Breid de volgende korte definitie voor het woo...   \n",
      "1  Breid de volgende korte definitie voor het woo...   \n",
      "2  Breid de volgende korte definitie voor het woo...   \n",
      "3  Breid de volgende korte definitie voor het woo...   \n",
      "4  Breid de volgende korte definitie voor het woo...   \n",
      "\n",
      "                                          prediction  \\\n",
      "0  maatschappij waarin mensen die niet tot hetzel...   \n",
      "1  alarmcentrale die bereikbaar is onder het tele...   \n",
      "2              bankbiljet met de waarde van 200 euro   \n",
      "3  monitor waarop driedimensionale beelden worden...   \n",
      "4  auto met de officiële status van een bromfiets...   \n",
      "\n",
      "                                           reference  \n",
      "0  maatschappij waarin mensen die niet tot hetzel...  \n",
      "1  alarmcentrale die bereikbaar is onder het tele...  \n",
      "2  bankbiljet dat de waarde van 200 euro vertegen...  \n",
      "3       monitor die driedimensionaal beeld weergeeft  \n",
      "4  motorvoertuig met de officiële status van een ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 3. GENERATE PREDICTIONS FOR THE TEST SET\n",
    "# ==============================================================================\n",
    "print(\"Loading test dataset and preparing for generation...\")\n",
    "dataset = load_dataset(config.DATASET_NAME, split=config.DATASET_TEST_SPLIT)\n",
    "\n",
    "# We will store the results here\n",
    "results = []\n",
    "\n",
    "# Helper function to create the correct prompt format for inference\n",
    "def create_inference_prompt(lemma, short_def):\n",
    "    chat = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Je bent een expert-lexicograaf die definities schrijft voor een Nederlands woordenboek.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"Breid de volgende korte definitie voor het woord \"\n",
    "                f\"'{lemma}' uit tot een volledige definitie: \"\n",
    "                f\"'{short_def}'\"\n",
    "            )\n",
    "        },\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "\n",
    "print(f\"Generating predictions for {len(dataset)} samples...\")\n",
    "# Process the dataset in batches for efficiency\n",
    "for i in tqdm(range(0, len(dataset), config.BATCH_SIZE)):\n",
    "    batch = dataset[i:i+config.BATCH_SIZE]\n",
    "    \n",
    "    # Create the input prompts by correctly iterating through the batch columns\n",
    "    prompts = [\n",
    "        create_inference_prompt(lemma, short_def)\n",
    "        for lemma, short_def in zip(batch['Lemma'], batch['DefinitionShort'])\n",
    "    ]\n",
    "    \n",
    "    # The 'source' for COMET is the user instruction part\n",
    "    sources = [p.split(\"<|user|>\")[1].split(\"<|assistant|>\")[0].strip() for p in prompts]\n",
    "    \n",
    "    # Tokenize the batch of prompts\n",
    "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=config.MAX_SEQ_LENGTH).to(\"cuda\")\n",
    "    \n",
    "    # Generate outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=config.MAX_SEQ_LENGTH, \n",
    "            num_beams=4, \n",
    "            early_stopping=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Decode the generated tokens\n",
    "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    \n",
    "    # For causal models, the output includes the prompt, so we must remove it.\n",
    "    predictions = [decoded.split(\"<|assistant|>\")[1].strip() for decoded in decoded_outputs]\n",
    "    \n",
    "    # Store the results\n",
    "    for j in range(len(predictions)):\n",
    "        results.append({\n",
    "            \"source\": sources[j],\n",
    "            \"prediction\": predictions[j],\n",
    "            \"reference\": batch['DefinitionFull'][j]\n",
    "        })\n",
    "\n",
    "# Convert results to a pandas DataFrame for easier handling\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nGeneration complete. Example result:\")\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee65e4a7-7934-4b9a-9bf9-ab7e918be96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe0ce83478f4639baf452faeaacc1e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ROUGE Scores ---\n",
      "{'rouge1': 0.4123357238171513, 'rouge2': 0.25161913131468583, 'rougeL': 0.38714679587966194, 'rougeLsum': 0.3870685910643292}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34cb8b054264765bf7b2cb1c360e7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e2e7d5e5624835ac827a15d590fa88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b442610e964894a95db24194f20b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BLEU Score ---\n",
      "{'bleu': 0.14475841666935474, 'precisions': [0.4588880566361418, 0.2604317684582334, 0.18081651588958478, 0.14115071315882674], 'brevity_penalty': 0.6159753773328359, 'length_ratio': 0.6736055728259631, 'translation_length': 41387, 'reference_length': 61441}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7e916b081b4e879dc98b8363615fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366d7777615a4edfb963529a88c13f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0afde275b5f48a58d10581146f5fe06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094cb773a5604e4a93f6929a1c26443e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9d4819f17640bda552bd3b598a9b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ebad6810ed4588abf2a03a8a02a21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BERTScore ---\n",
      "   Average Precision: 0.8003\n",
      "      Average Recall: 0.7623\n",
      "          Average F1: 0.7795\n",
      "\n",
      "--- COMET Scores ---\n",
      "Loading COMET models (this may take a while)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22aa71ce9cd48beb36bb8f4a43bbe10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15dac421bb04528a21d8d5301ef9b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150c18f080b84adea14eb407d26cb62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "checkpoints/model.ckpt:   0%|          | 0.00/2.32G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35a1e90203f410b8b8c1484f8cdfe87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hparams.yaml:   0%|          | 0.00/567 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85b060dde71464085d81ff3cee7362e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458ce852052b453c9e93df0c218f01b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af60ec40915b479b8a470a2a3deb9f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c519534ee94967bdaec94ee95d2cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1958838e2c5476f95871cc0517b92f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f3beef714447b78d70b4aba583e33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0236116368804b2b89036d5d493c42c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e987f01f5de4669be890749271851df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78d6921dcac448f83b5a7338302e9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba710df07ee346829da2ca7604a41ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28d07f38157443ebbec4ae638b1e5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607db8c15ef5494f881ab02cc6db77ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "checkpoints/model.ckpt:   0%|          | 0.00/2.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd6288da1e64993a5dba83247652cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hparams.yaml:   0%|          | 0.00/716 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.8.2 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/huggingface/hub/models--Unbabel--wmt22-cometkiwi-da/snapshots/1ad785194e391eebc6c53e2d0776cada8f83179a/checkpoints/model.ckpt`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c825b708f8c45758559b054714f5166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3b875889db49ff8c9afa21a60240cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2004a920d4542aa9dd5ecbf656b2784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/513 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b508848f0a4b3387de7e5a8c013f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4911dc241443eea56d2d7ab7a73f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "checkpoints/model.ckpt:   0%|          | 0.00/13.9G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418f9ed5d05e43aaa6f97114ea2cf775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555a117e052747d2b7c9de7a116d590c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5168e4c9c96548dcb9879ac73e4d8a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54269cb3cc174e039e6e21316ac0bcd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hparams.yaml:   0%|          | 0.00/988 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9e2a86ef5f46e79397377b412ac40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/405 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c13d4ba8d9041fe8af07a5e6d1a23d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb4123c0dd34a08be2b48327d4689d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfebd5e7e1714f18aa1a0991cccffb48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/238 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5d2dbf94be40b8a032404325020975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- COMET-22 Score ---\n",
      "               score: 0.6661\n",
      "\n",
      "--- COMETkiwi Score ---\n",
      "               score: 0.6462\n",
      "\n",
      "--- XCOMET Score ---\n",
      "               score: 0.7354\n",
      "\n",
      "Saving results to disk...\n",
      "Summary of scores saved to: ./evaluation_summary_geitje.txt\n",
      "\n",
      "Evaluation finished.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 4. CALCULATE AND DISPLAY METRICS\n",
    "# ==============================================================================\n",
    "print(\"Calculating evaluation metrics...\")\n",
    "\n",
    "# Extract lists of predictions, references, and sources from the DataFrame\n",
    "predictions = results_df[\"prediction\"].tolist()\n",
    "references = results_df[\"reference\"].tolist()\n",
    "sources = results_df[\"source\"].tolist()\n",
    "\n",
    "# --- ROUGE ---\n",
    "rouge = evaluate.load('rouge')\n",
    "rouge_results = rouge.compute(predictions=predictions, references=references)\n",
    "print(\"\\n--- ROUGE Scores ---\")\n",
    "print(rouge_results)\n",
    "\n",
    "# --- BLEU ---\n",
    "bleu = evaluate.load('bleu')\n",
    "# Note: BLEU expects references to be a list of lists\n",
    "bleu_results = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "print(\"\\n--- BLEU Score ---\")\n",
    "print(bleu_results)\n",
    "\n",
    "# --- BERTScore ---\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "bertscore_results = bertscore.compute(predictions=predictions, references=references, lang=\"nl\")\n",
    "\n",
    "avg_precision = sum(bertscore_results['precision']) / len(bertscore_results['precision'])\n",
    "avg_recall = sum(bertscore_results['recall']) / len(bertscore_results['recall'])\n",
    "avg_f1 = sum(bertscore_results['f1']) / len(bertscore_results['f1'])\n",
    "\n",
    "print(f\"\\n--- BERTScore ---\")\n",
    "print(f\"{'Average Precision':>20}: {avg_precision:.4f}\")\n",
    "print(f\"{'Average Recall':>20}: {avg_recall:.4f}\")\n",
    "print(f\"{'Average F1':>20}: {avg_f1:.4f}\")\n",
    "\n",
    "# --- COMET ---\n",
    "print(\"\\n--- COMET Scores ---\")\n",
    "print(\"Loading COMET models (this may take a while)...\")\n",
    "comet_22 = evaluate.load('comet', 'Unbabel/wmt22-comet-da')\n",
    "comet_kiwi = evaluate.load('comet', 'Unbabel/wmt22-cometkiwi-da')\n",
    "xcomet = evaluate.load('comet', 'Unbabel/XCOMET-XL')\n",
    "\n",
    "comet_22_results = comet_22.compute(predictions=predictions, references=references, sources=sources)\n",
    "comet_kiwi_results = comet_kiwi.compute(predictions=predictions, references=references, sources=sources)\n",
    "xcomet_results = xcomet.compute(predictions=predictions, references=references, sources=sources)\n",
    "\n",
    "print(f\"\\n--- COMET-22 Score ---\")\n",
    "print(f\"{'score':>20}: {comet_22_results['mean_score']:.4f}\")\n",
    "print(f\"\\n--- COMETkiwi Score ---\")\n",
    "print(f\"{'score':>20}: {comet_kiwi_results['mean_score']:.4f}\")\n",
    "print(f\"\\n--- XCOMET Score ---\")\n",
    "print(f\"{'score':>20}: {xcomet_results['mean_score']:.4f}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. SAVE RESULTS TO DISK\n",
    "# ==============================================================================\n",
    "print(\"\\nSaving results to disk...\")\n",
    "\n",
    "# --- Save the summary scores to a text file ---\n",
    "summary_path = \"./evaluation_summary_geitje.txt\"\n",
    "with open(summary_path, \"w\") as f:\n",
    "    f.write(\"--- ROUGE Scores ---\\n\")\n",
    "    f.write(str(rouge_results) + \"\\n\")\n",
    "    f.write(\"\\n--- BLEU Score ---\\n\")\n",
    "    f.write(str(bleu_results) + \"\\n\")\n",
    "    f.write(\"\\n--- BERTScore ---\\n\")\n",
    "    f.write(f\"{'Average Precision':>20}: {avg_precision:.4f}\\n\")\n",
    "    f.write(f\"{'Average Recall':>20}: {avg_recall:.4f}\\n\")\n",
    "    f.write(f\"{'Average F1':>20}: {avg_f1:.4f}\\n\")\n",
    "    f.write(\"\\n--- COMET-22 Score ---\\n\")\n",
    "    f.write(f\"{'score':>20}: {comet_22_results['mean_score']:.4f}\\n\")\n",
    "    f.write(\"\\n--- COMETkiwi Score ---\\n\")\n",
    "    f.write(f\"{'score':>20}: {comet_kiwi_results['mean_score']:.4f}\\n\")\n",
    "    f.write(\"\\n--- XCOMET Score ---\\n\")\n",
    "    f.write(f\"{'score':>20}: {xcomet_results['mean_score']:.4f}\\n\")\n",
    "\n",
    "print(f\"Summary of scores saved to: {summary_path}\")\n",
    "print(\"\\nEvaluation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde55c85-ed61-427b-ae7f-9d2ed8323a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating a detailed results file with per-entry scores ---\n",
      "\n",
      "Successfully created and saved the detailed results file.\n",
      "File saved to: ./evaluation_results_per_entry_geitje.tsv\n",
      "\n",
      "--- Data Preview ---\n",
      "Note: BLEU and ROUGE are corpus-level metrics and are not included in this per-entry file.\n",
      "                   Lemma          POS MeaningNumber  LemmaID  MeaningID  \\\n",
      "0  1,5 metermaatschappij  substantief           1.0   909355     909359   \n",
      "1           112-centrale  substantief           1.0      313        314   \n",
      "2         200 eurobiljet  substantief           1.0   495566     495570   \n",
      "3             3D-monitor  substantief           1.0   232019     232022   \n",
      "4      45 kilometerwagen  substantief           1.0   871087     871098   \n",
      "\n",
      "                                      DefinitionFull  \\\n",
      "0  maatschappij waarin mensen die niet tot hetzel...   \n",
      "1  alarmcentrale die bereikbaar is onder het tele...   \n",
      "2  bankbiljet dat de waarde van 200 euro vertegen...   \n",
      "3       monitor die driedimensionaal beeld weergeeft   \n",
      "4  motorvoertuig met de officiële status van een ...   \n",
      "\n",
      "                                DefinitionShort  \\\n",
      "0  maatschappij waarin fysieke afstand nodig is   \n",
      "1                                 alarmcentrale   \n",
      "2                           biljet van 200 euro   \n",
      "3                          monitor met 3D-beeld   \n",
      "4                  autootje met bromfietsstatus   \n",
      "\n",
      "                                    model_prediction  bertscore_precision  \\\n",
      "0  maatschappij waarin mensen die niet tot hetzel...             0.941304   \n",
      "1  alarmcentrale die bereikbaar is onder het tele...             1.000000   \n",
      "2              bankbiljet met de waarde van 200 euro             0.914980   \n",
      "3  monitor waarop driedimensionale beelden worden...             0.845633   \n",
      "4  auto met de officiële status van een bromfiets...             0.979325   \n",
      "\n",
      "   bertscore_recall  bertscore_f1  comet22_score  cometkiwi_score  \\\n",
      "0          0.942552      0.941928       0.907140         0.751417   \n",
      "1          1.000000      1.000000       0.979387         0.726491   \n",
      "2          0.814931      0.862062       0.892582         0.654504   \n",
      "3          0.854885      0.850234       0.826405         0.815245   \n",
      "4          0.957879      0.968483       0.817032         0.409089   \n",
      "\n",
      "   xcomet_score  \n",
      "0      0.963953  \n",
      "1      0.956617  \n",
      "2      0.946028  \n",
      "3      0.952870  \n",
      "4      0.944420  \n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 6. CREATE AND SAVE DETAILED PER-ENTRY RESULTS TSV\n",
    "# ==============================================================================\n",
    "print(\"--- Creating a detailed results file with per-entry scores ---\")\n",
    "\n",
    "try:\n",
    "    # Convert the original test set to a pandas DataFrame\n",
    "    final_results_df = dataset.to_pandas()\n",
    "\n",
    "    # Add the model's predictions from the generation step\n",
    "    final_results_df['model_prediction'] = results_df['prediction']\n",
    "\n",
    "    # --- Add Per-Entry Metric Scores ---\n",
    "    # Add BERTScore (Precision, Recall, and F1)\n",
    "    final_results_df['bertscore_precision'] = bertscore_results['precision']\n",
    "    final_results_df['bertscore_recall'] = bertscore_results['recall']\n",
    "    final_results_df['bertscore_f1'] = bertscore_results['f1']\n",
    "    \n",
    "    # Add COMET-22, CometKiwi and XCOMET scores\n",
    "    final_results_df['comet22_score'] = comet_22_results['scores']\n",
    "    final_results_df['cometkiwi_score'] = comet_kiwi_results['scores']\n",
    "    final_results_df['xcomet_score'] = xcomet_results['scores']\n",
    "\n",
    "    # --- Save to TSV File ---\n",
    "    tsv_path = \"./evaluation_results_per_entry_geitje.tsv\"\n",
    "    final_results_df.to_csv(tsv_path, sep='\\t', index=False)\n",
    "\n",
    "    print(f\"\\nSuccessfully created and saved the detailed results file.\")\n",
    "    print(f\"File saved to: {tsv_path}\")\n",
    "    \n",
    "    print(\"\\n--- Data Preview ---\")\n",
    "    print(\"Note: BLEU and ROUGE are corpus-level metrics and are not included in this per-entry file.\")\n",
    "    print(final_results_df.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred while creating the TSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45661e-5e0d-4182-8569-d44e2b8c5a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
